import cv2
import numpy as np
from typing import List, Tuple, Dict, Optional

class OpticalFormReader:
    """
    OpenCV kullanarak optik form okuma sÄ±nÄ±fÄ±
    """
    
    def __init__(self):
        # OMR BUBBLE PARAMETRELERÄ° - LGS FORMU Ä°Ã‡Ä°N OPTÄ°MÄ°ZE EDÄ°LDÄ°
        # LGS formundaki YUVARLAK kutucuklar - SADECE GERÃ‡EKTEKÄ° OMR BUBBLES!
        # GERÃ‡EK LGS formunda bubbles uniform boyutta
        self.min_bubble_area = 40         # Minimum alan - biraz daha dÃ¼ÅŸÃ¼k
        self.max_bubble_area = 300        # Maximum alan - biraz daha geniÅŸ
        self.threshold_value = 180        # Sabit threshold (uygun)
        self.filled_threshold = 0.65      # DEPRECATED - adaptive fill kullanÄ±lÄ±yor
        
        # Yeni parametreler - SADECE YUVARLAK OMR BUBBLES iÃ§in OPTÄ°MÄ°ZE
        self.min_circularity = 0.70       # Dairesellik eÅŸiÄŸi - YÃœKSEK ama gerÃ§ekÃ§i
        self.aspect_ratio_range = (0.7, 1.4)  # En-boy oranÄ± - DAR ama esnek
        self.grid_tolerance = 20          # SatÄ±r/sÃ¼tun gruplama toleransÄ±
        self.min_fill_ratio = 0.35        # Ä°Ã§i dolu kabul etme eÅŸiÄŸi (35% beyaz piksel)
    
    def preprocess_image(self, image):
        """
        OMR iÃ§in optimize edilmiÅŸ gÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme
        
        CRITICAL FIX: Uses ADAPTIVE THRESHOLD with BINARY_INV
        - Black background (paper) â†’ 0
        - White foreground (bubbles/marks) â†’ 255
        
        DeÄŸiÅŸiklikler:
        1. Contrast artÄ±rma (CLAHE) - ZayÄ±f Ä±ÅŸÄ±kta bile bubble'larÄ± gÃ¶rÃ¼r
        2. Daha bÃ¼yÃ¼k GaussianBlur (7,7) - GÃ¼rÃ¼ltÃ¼yÃ¼ daha iyi temizler
        3. Bilateral filter - KenarlarÄ± koruyarak gÃ¼rÃ¼ltÃ¼ temizler
        4. Adaptive threshold with BINARY_INV - Varyasyonlu Ä±ÅŸÄ±klandÄ±rmada Ã§alÄ±ÅŸÄ±r
        5. Daha bÃ¼yÃ¼k morfolojik kernel - KÃ¼Ã§Ã¼k kesikleri kapatÄ±r
        """
        print("\nğŸ”§ PREPROCESSING IMAGE:")
        
        # 1. Gri tonlamaya Ã§evir
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        print(f"   Step 1: Converted to grayscale - shape: {gray.shape}")
        
        # 2. CLAHE (Contrast Limited Adaptive Histogram Equalization)
        # KontrastÄ± artÄ±rarak zayÄ±f Ä±ÅŸÄ±kta bile bubble'larÄ± belirginleÅŸtirir
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        print(f"   Step 2: CLAHE applied - intensity range: [{gray.min()}, {gray.max()}]")
        
        # 3. Bilateral filter - LGS KÃœÃ‡ÃœK KUTUCUKLAR Ä°Ã‡Ä°N HAFÄ°FLETÄ°LDÄ°
        # Daha kÃ¼Ã§Ã¼k kernel: KÃ¼Ã§Ã¼k detaylarÄ± korur
        denoised = cv2.bilateralFilter(gray, 5, 50, 50)  # Was 9, 75, 75
        print(f"   Step 3: Bilateral filter applied (gentle, preserves small details)")
        
        # 4. GaussianBlur - LGS Ä°Ã‡Ä°N HAFÄ°F
        # (5,5) kernel: KÃ¼Ã§Ã¼k kutucuklarÄ± bulanÄ±klaÅŸtÄ±rmamak iÃ§in (was 7,7)
        blurred = cv2.GaussianBlur(denoised, (5, 5), 0)
        print(f"   Step 4: Gaussian blur applied (5x5, preserves tiny bubbles)")
        
        # 5. CRITICAL: Adaptive threshold with BINARY_INV - LGS FORMU Ä°Ã‡Ä°N
        # blockSize=11: KÃ¼Ã§Ã¼k kutucuklar iÃ§in daha kÃ¼Ã§Ã¼k pencere (was 21)
        # C=8: Daha hassas threshold (was 10)
        # THRESH_BINARY_INV: Inverts result so WHITE paper â†’ BLACK background
        #                     and DARK marks/bubbles â†’ WHITE foreground
        print(f"   Step 5: Applying adaptive threshold (LGS optimized)...")
        print(f"           - blockSize: 11 (smaller windows for tiny bubbles)")
        print(f"           - C: 8 (sensitive threshold for small marks)")
        print(f"           - Mode: THRESH_BINARY_INV (white paper â†’ black bg)")
        
        thresh = cv2.adaptiveThreshold(
            blurred, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 11, 8
        )
        
        # Check result
        white_pixels = cv2.countNonZero(thresh)
        total_pixels = thresh.size
        white_ratio = white_pixels / total_pixels
        print(f"   Result: {white_pixels}/{total_pixels} white pixels ({white_ratio:.1%})")
        
        if white_ratio > 0.5:
            print(f"   âš ï¸  WARNING: >50% white pixels! Image might NOT be inverted properly")
            print(f"   Expected: Black background (paper) with white bubbles (marks)")
        else:
            print(f"   âœ“ Good: <50% white pixels (bubbles/marks on black background)")
        
        # 6-7. MORFOLOJÄ°K Ä°ÅLEMLER KALDIRILDI!
        # SEBEP: LGS formundaki kÃ¼Ã§Ã¼k ve yoÄŸun bubble'lar birbirine Ã§ok yakÄ±n
        #        CLOSE iÅŸlemi bubble'larÄ± birleÅŸtiriyor â†’ tek dev kontÃ¼r oluÅŸuyor
        #        OPEN iÅŸlemi kÃ¼Ã§Ã¼k bubble'larÄ± tamamen siliyor
        # Ã‡Ã–ZÃœM: Morfolojik iÅŸlem YAPMA, doÄŸrudan threshold Ã§Ä±ktÄ±sÄ±nÄ± kullan
        print(f"   Step 6-7: Morphological operations SKIPPED (preserves tiny, dense bubbles)")
        
        print(f"âœ… Preprocessing complete\n")
        return thresh
    
    def find_form_contours(self, image):
        """
        OMR bubble kontÃ¼rlerini bul
        
        DeÄŸiÅŸiklikler:
        1. Daha bÃ¼yÃ¼k kernel (5,5) - Bubble iÃ§indeki boÅŸluklarÄ± kapat
        2. RETR_TREE yerine RETR_EXTERNAL - Sadece dÄ±ÅŸ kontÃ¼rler (daha hÄ±zlÄ±)
        3. CHAIN_APPROX_SIMPLE - Bellek tasarrufu
        
        CONTOUR DETECTION STRATEGY:
        - RETR_EXTERNAL: We only need outer contours of bubbles. Using RETR_TREE
          or RETR_CCOMP would give us nested hierarchies (e.g., filled bubbles with
          inner contours), which is unnecessary and slower.
        - CHAIN_APPROX_SIMPLE: Compresses contour points (e.g., straight lines stored
          as 2 endpoints instead of all pixels). Reduces memory without losing accuracy.
        """
        # Morfolojik closing: LGS KÃœÃ‡ÃœK KUTUCUKLAR Ä°Ã‡Ä°N OPTÄ°MÄ°ZE
        # (3,3) ELLIPSE kernel: KÃ¼Ã§Ã¼k kutucuklarÄ± birleÅŸtirmemek iÃ§in (was 5,5)
        # iterations=1: Daha hafif iÅŸlem (was 2)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        morphed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=1)
        
        # DEBUG: Save morphological result
        cv2.imwrite('debug_morphed.jpg', morphed)
        print("ğŸ’¾ Saved: debug_morphed.jpg (LGS: 3x3 kernel, 1 iteration)")
        
        # KontÃ¼rleri bul
        # RETR_EXTERNAL: Sadece en dÄ±ÅŸ kontÃ¼rler (hÄ±z optimizasyonu)
        # CHAIN_APPROX_SIMPLE: KontÃ¼r noktalarÄ±nÄ± sÄ±kÄ±ÅŸtÄ±r (bellek optimizasyonu)
        contours, _ = cv2.findContours(
            morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        return contours
    
    def filter_bubble_contours(self, contours, image_shape):
        """
        OMR bubble'larÄ±nÄ± filtrele (geliÅŸmiÅŸ) - WITH DEBUG OUTPUT
        
        Ä°yileÅŸtirmeler:
        1. Dairesellik kontrolÃ¼ eklendi - Kalem lekeleri elemek iÃ§in
        2. Solidity kontrolÃ¼ - Ä°Ã§i boÅŸ ÅŸekilleri yoksay
        3. Konvexity - DÃ¼zensiz ÅŸekilleri eleme
        4. Minimum piksel yoÄŸunluÄŸu - Ã‡ok kÃ¼Ã§Ã¼k nesneleri atla
        
        DEBUG MODE: Prints details of every contour examined
        """
        bubbles = []
        
        # LGS FORMU Ä°Ã‡Ä°N OPTÄ°MÄ°ZE EDÄ°LMÄ°Å PARAMETRELERÄ° KULLAN
        min_area_debug = self.min_bubble_area  # 20 pixels
        max_area_debug = self.max_bubble_area  # 800 pixels
        
        print(f"\nğŸ” FILTERING {len(contours)} CONTOURS (STRICT OMR BUBBLE DETECTION):")
        print(f"   SADECE OMR BUBBLES ARANIR - diÄŸer tÃ¼m ÅŸekiller reddedilir!")
        print(f"   Area range: {min_area_debug}-{max_area_debug} pixels (UNIFORM bubble size)")
        print(f"   Aspect ratio: {self.aspect_ratio_range} (SQUARE-like)")
        print(f"   Min circularity: {self.min_circularity} (HIGH - circular shapes only!)")
        print(f"   Min solidity: 0.80 (HIGH - solid filled shapes only!)")
        print(f"   Fill detection threshold: {self.min_fill_ratio} (for marked/unmarked)")
        print("=" * 80)
        
        for idx, contour in enumerate(contours, 1):
            # Kontur alanÄ±
            area = cv2.contourArea(contour)
            
            # Konturun etrafÄ±na dikdÃ¶rtgen Ã§iz
            x, y, w, h = cv2.boundingRect(contour)
            
            # En-boy oranÄ± kontrolÃ¼ (kare/dikdÃ¶rtgen olmalÄ±)
            aspect_ratio = w / float(h) if h > 0 else 0
            
            # Dairesellik (Circularity) kontrolÃ¼
            perimeter = cv2.arcLength(contour, True)
            circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0
            
            # Solidity: Kontur alanÄ± / Konveks gÃ¶vde alanÄ±
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            
            # DEBUG: Print details for EVERY contour
            status = "âœ“ ACCEPTED"
            rejection_reason = ""
            
            # Alan kontrolÃ¼ (RELAXED)
            if not (min_area_debug < area < max_area_debug):
                status = "âœ— REJECTED"
                if area <= min_area_debug:
                    rejection_reason = f"Area too small ({area:.0f} â‰¤ {min_area_debug})"
                else:
                    rejection_reason = f"Area too large ({area:.0f} â‰¥ {max_area_debug})"
            # En-boy oranÄ± kontrolÃ¼
            elif not (self.aspect_ratio_range[0] < aspect_ratio < self.aspect_ratio_range[1]):
                status = "âœ— REJECTED"
                rejection_reason = f"Aspect ratio out of range ({aspect_ratio:.2f})"
            # Dairesellik kontrolÃ¼ - SADECE YUVARLAKLAR (0.70+ = yuvarlak ÅŸekiller)
            elif circularity < self.min_circularity:
                status = "âœ— REJECTED"
                rejection_reason = f"Circularity too low ({circularity:.2f} < {self.min_circularity})"
            # Solidity kontrolÃ¼ - Dolu yuvarlak kutular iÃ§in SIKI
            elif solidity < 0.80:  # 0.80+ = iÃ§i dolu, dÃ¼zgÃ¼n ÅŸekil
                status = "âœ— REJECTED"
                rejection_reason = f"Solidity too low ({solidity:.2f} < 0.80)"
            elif perimeter == 0 or hull_area == 0:
                status = "âœ— REJECTED"
                rejection_reason = "Invalid contour (perimeter or hull_area = 0)"
            
            # Print contour details
            print(f"Contour #{idx:3d}: Area={area:6.0f}, Ratio={aspect_ratio:.2f}, "
                  f"Circ={circularity:.2f}, Sol={solidity:.2f} -> {status}")
            if rejection_reason:
                print(f"              {rejection_reason}")
            
            # Add to bubbles if passed all checks
            if status == "âœ“ ACCEPTED":
                bubbles.append({
                    'contour': contour,
                    'x': x,
                    'y': y,
                    'w': w,
                    'h': h,
                    'area': area,
                    'center': (x + w // 2, y + h // 2),
                    'circularity': circularity,
                    'solidity': solidity,
                    'aspect_ratio': aspect_ratio,
                    'is_filled': False  # Daha sonra hesaplanacak
                })
        
        print("=" * 80)
        print(f"âœ… FINAL RESULT: {len(bubbles)} bubbles accepted out of {len(contours)} contours\n")
        
        return bubbles
    
    def get_bubble_fill_ratio(self, image, bubble):
        """
        KutucuÄŸun doluluk oranÄ±nÄ± hesapla (0.0 - 1.0)
        
        KRITIK: Preprocessed image'da BEYAZ = iÅŸaretlenmiÅŸ alan (BINARY_INV)
                Siyah arka plan + beyaz iÅŸaretler
        
        Ä°yileÅŸtirmeler:
        1. ROI padding - Kenar etkisini azaltÄ±r
        2. ROI ortasÄ± kontrolÃ¼ - Kenar gÃ¶lgeleri yanlÄ±ÅŸ pozitif vermez
        3. Normalized fill ratio - KarÅŸÄ±laÅŸtÄ±rma iÃ§in kullanÄ±labilir
        
        Returns:
            float: Doluluk oranÄ± (0.0 = boÅŸ, 1.0 = tamamen dolu)
        """
        x, y, w, h = bubble['x'], bubble['y'], bubble['w'], bubble['h']
        
        # ROI padding: Kenarlardan %15 iÃ§eri gir (kenar gÃ¶lgelerini yoksay)
        padding_x = int(w * 0.15)
        padding_y = int(h * 0.15)
        
        x_start = max(0, x + padding_x)
        y_start = max(0, y + padding_y)
        x_end = min(image.shape[1], x + w - padding_x)
        y_end = min(image.shape[0], y + h - padding_y)
        
        # KutucuÄŸun ORTASINI al (kenar etkisiz)
        roi = image[y_start:y_end, x_start:x_end]
        
        if roi.size == 0:
            return 0.0
        
        # ROI iÃ§indeki BEYAZ piksel sayÄ±sÄ± (preprocessed BINARY_INV: white = filled)
        total_pixels = roi.size
        white_pixels = cv2.countNonZero(roi)
        
        # Doldurulma oranÄ±: Beyaz piksel oranÄ±
        fill_ratio = white_pixels / total_pixels
        
        return fill_ratio
    
    def check_if_filled_adaptive(self, image, row_bubbles: List[Dict], bubble_idx: int) -> bool:
        """
        ADAPTIVE fill detection: KutucuÄŸun iÅŸaretli olup olmadÄ±ÄŸÄ±nÄ± satÄ±r ortalamasÄ±na gÃ¶re belirle
        
        ALGORITHM:
        1. Calculate fill ratio for all bubbles in the row
        2. Compute mean and standard deviation
        3. A bubble is "filled" if its fill ratio is significantly above the mean
        
        This adapts to:
        - Different lighting conditions
        - Different scanning qualities
        - Different marking instruments (pen vs pencil)
        
        Args:
            image: Preprocessed image
            row_bubbles: All bubbles in the current row
            bubble_idx: Index of the bubble to check
        
        Returns:
            bool: True if bubble is marked, False otherwise
        """
        # Calculate fill ratios for all bubbles in the row
        fill_ratios = [self.get_bubble_fill_ratio(image, b) for b in row_bubbles]
        
        if not fill_ratios:
            return False
        
        current_fill = fill_ratios[bubble_idx]
        
        # Calculate statistics
        mean_fill = np.mean(fill_ratios)
        std_fill = np.std(fill_ratios)
        
        # ADAPTIVE THRESHOLD: A bubble is filled if it's significantly above average
        # Use mean + 1.0 * std_dev as threshold (was 1.5 - too strict)
        # This means the bubble must be at least 1.0 standard deviations above the mean
        threshold = mean_fill + (1.0 * std_fill)
        
        # Also require minimum absolute fill ratio (0.35) to avoid false positives
        # This is the CRITICAL parameter - iÅŸaretli kutular en az %35 beyaz piksel iÃ§ermeli
        min_absolute_fill = self.min_fill_ratio  # 0.3 from __init__
        
        is_filled = (current_fill > threshold) and (current_fill > min_absolute_fill)
        
        # Debug output for the row (only once per row)
        if bubble_idx == 0:
            print(f"      Fill stats - Mean: {mean_fill:.3f}, Std: {std_fill:.3f}, Threshold: {threshold:.3f}")
            print(f"      Ratios: {[f'{r:.3f}' for r in fill_ratios]}")
        
        return is_filled
    
    def check_if_filled(self, image, bubble):
        """
        DEPRECATED: Legacy method using hardcoded threshold
        Use check_if_filled_adaptive() instead for better results
        
        Kept for backwards compatibility with older code
        """
        fill_ratio = self.get_bubble_fill_ratio(image, bubble)
        
        # Hardcoded threshold: %65 doluluk = iÅŸaretli
        # âš ï¸ WARNING: This fails under different lighting conditions!
        return fill_ratio > self.filled_threshold
    
    def group_bubbles_by_row(self, bubbles, tolerance=20):
        """
        KutucuklarÄ± satÄ±rlara gÃ¶re grupla - STRICT row-then-column ordering
        
        ALGORITHM:
        1. Sort all bubbles by Y coordinate (top to bottom)
        2. Group bubbles with similar Y values into rows (tolerance-based)
        3. Sort each row by X coordinate (left to right)
        
        Args:
            bubbles: Kutucuk listesi
            tolerance: Y koordinatÄ± toleransÄ± (piksel)
        
        Returns:
            SatÄ±rlara gÃ¶re gruplandÄ±rÄ±lmÄ±ÅŸ kutucuklar (strict ordering)
        """
        if not bubbles:
            return []
        
        # Phase 1: Sort by Y coordinate (top to bottom) - PRIMARY SORT
        sorted_bubbles = sorted(bubbles, key=lambda b: b['y'])
        
        rows = []
        current_row = [sorted_bubbles[0]]
        current_row_y_avg = sorted_bubbles[0]['y']
        
        for bubble in sorted_bubbles[1:]:
            # Calculate average Y of current row for more stable grouping
            current_row_y_avg = sum(b['y'] for b in current_row) / len(current_row)
            
            # If Y coordinate is within tolerance of current row average, add to row
            if abs(bubble['y'] - current_row_y_avg) <= tolerance:
                current_row.append(bubble)
            else:
                # Phase 2: Sort current row by X coordinate (left to right) - SECONDARY SORT
                current_row.sort(key=lambda b: b['x'])
                rows.append(current_row)
                
                # Start new row
                current_row = [bubble]
                current_row_y_avg = bubble['y']
        
        # Don't forget last row
        if current_row:
            current_row.sort(key=lambda b: b['x'])
            rows.append(current_row)
        
        # Debug output for verification
        print(f"ğŸ“Š Bubble Grouping Summary:")
        print(f"   Total bubbles: {len(bubbles)}")
        print(f"   Rows detected: {len(rows)}")
        for i, row in enumerate(rows, 1):
            print(f"   Row {i}: {len(row)} bubbles (Y avg: {sum(b['y'] for b in row) / len(row):.1f})")
        
        return rows
    
    def detect_answers(self, image_path: str, expected_questions: int = 20, 
                      options_per_question: int = 5) -> Dict:
        """
        OMR formu oku ve cevaplarÄ± tespit et
        
        Ã–NEMLÄ°: Perspektif dÃ¼zeltme otomatik uygulanÄ±r!
        
        Args:
            image_path: GÃ¶rÃ¼ntÃ¼ dosya yolu
            expected_questions: Beklenen soru sayÄ±sÄ±
            options_per_question: Her soru iÃ§in seÃ§enek sayÄ±sÄ± (A,B,C,D,E = 5)
        
        Returns:
            Dict: Tespit edilen cevaplar ve meta bilgiler
        """
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ oku
            image = cv2.imread(image_path)
            if image is None:
                return {'error': 'GÃ¶rÃ¼ntÃ¼ okunamadÄ±'}
            
            original_shape = image.shape
            
            # Ã–NEMLÄ°: Ä°lk Ã¶nce form kÃ¶ÅŸelerini bul ve perspektif dÃ¼zelt
            # Timing mark bazlÄ± yÃ¶ntem Ã¶ncelikli!
            if isinstance(self, AdvancedFormReader):
                # Ã–nce timing mark bazlÄ± metodu dene
                corners = self.detect_form_corners_with_timing_marks(image)
                
                if corners is not None:
                    print("ğŸ“ Form kÃ¶ÅŸeleri bulundu (timing mark bazlÄ±), perspektif dÃ¼zeltiliyor...")
                    image = self.apply_perspective_transform(image, corners)
                else:
                    print("âš ï¸ Form kÃ¶ÅŸeleri bulunamadÄ±, orijinal gÃ¶rÃ¼ntÃ¼ kullanÄ±lÄ±yor")
            
            # Ã–n iÅŸleme (optimize edilmiÅŸ OMR preprocessing)
            processed = self.preprocess_image(image)
            
            # DEBUG: Save the INVERTED binary image
            cv2.imwrite('debug_binary_input_fixed.jpg', processed)
            print("ğŸ’¾ Saved: debug_binary_input_fixed.jpg (INVERTED: black bg, white bubbles)")
            print(f"   Image shape: {processed.shape}")
            print(f"   Unique pixel values: {np.unique(processed)}")
            
            # Verify inversion
            white_pixel_count = cv2.countNonZero(processed)
            total_pixels = processed.size
            print(f"   White pixels: {white_pixel_count}/{total_pixels} ({white_pixel_count/total_pixels:.1%})")
            if white_pixel_count / total_pixels > 0.5:
                print("   âš ï¸  WARNING: Most pixels are WHITE - inversion may have failed!")
                print("   Expected: Black background (paper) with white foreground (bubbles)")
            else:
                print("   âœ“ Looks good: Black background with white objects")
            
            # KontÃ¼rleri bul - TÃœM kontÃ¼rleri al (RETR_LIST kullan)
            # RETR_EXTERNAL sadece en dÄ±ÅŸ kontÃ¼rÃ¼ buluyor â†’ tÃ¼m form 1 kontÃ¼r
            # RETR_LIST tÃ¼m kontÃ¼rleri buluyor â†’ her bubble ayrÄ± kontÃ¼r
            contours, _ = cv2.findContours(processed, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            print(f"\nğŸ” RAW CONTOURS: {len(contours)} contours found (RETR_LIST mode)")
            
            # KutucuklarÄ± filtrele
            bubbles = self.filter_bubble_contours(contours, image.shape)
            
            # DEBUG: Draw detected bubbles on original
            debug_bubbles = image.copy()
            for bubble in bubbles:
                x, y, w, h = bubble['x'], bubble['y'], bubble['w'], bubble['h']
                cv2.rectangle(debug_bubbles, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.imwrite('debug_bubbles.jpg', debug_bubbles)
            print(f"ğŸ’¾ Saved: debug_bubbles.jpg ({len(bubbles)} bubbles detected)")
            
            if len(bubbles) == 0:
                return {'error': 'Kutucuk bulunamadÄ±. LÃ¼tfen daha net bir fotoÄŸraf Ã§ekin.'}
            
            # VALIDATE: Check expected bubble count
            expected_bubble_count = expected_questions * options_per_question
            print(f"\nğŸ” Bubble Count Validation:")
            print(f"   Expected: {expected_bubble_count} bubbles ({expected_questions} questions Ã— {options_per_question} options)")
            print(f"   Detected: {len(bubbles)} bubbles")
            
            if len(bubbles) < expected_bubble_count:
                print(f"   âš ï¸  WARNING: Detected fewer bubbles than expected!")
                print(f"   Missing: {expected_bubble_count - len(bubbles)} bubbles")
                print(f"   Possible causes: Poor image quality, incorrect filtering, occlusion")
            elif len(bubbles) > expected_bubble_count:
                print(f"   âš ï¸  WARNING: Detected more bubbles than expected!")
                print(f"   Extra: {len(bubbles) - expected_bubble_count} bubbles")
                print(f"   Possible causes: Dust, text detected as bubbles, loose filtering")
            else:
                print(f"   âœ… Perfect match!")
            
            # SatÄ±rlara gÃ¶re grupla
            rows = self.group_bubbles_by_row(bubbles)
            
            # DEBUG: Visualize row grouping
            debug_rows = image.copy()
            colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
            for row_idx, row in enumerate(rows):
                color = colors[row_idx % len(colors)]
                for bubble in row:
                    x, y, w, h = bubble['x'], bubble['y'], bubble['w'], bubble['h']
                    cv2.rectangle(debug_rows, (x, y), (x+w, y+h), color, 2)
                    cv2.putText(debug_rows, f"R{row_idx+1}", (x, y-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            cv2.imwrite('debug_rows.jpg', debug_rows)
            print(f"ğŸ’¾ Saved: debug_rows.jpg (rows color-coded)")
            
            # VALIDATE: Check row count
            if len(rows) != expected_questions:
                print(f"\nâš ï¸  Row Count Mismatch:")
                print(f"   Expected rows: {expected_questions}")
                print(f"   Detected rows: {len(rows)}")
                print(f"   This may indicate Y-coordinate grouping issues")
            
            # CevaplarÄ± tespit et
            answers = {}
            option_letters = ['A', 'B', 'C', 'D', 'E', 'F']
            
            for question_num, row in enumerate(rows, 1):
                if question_num > expected_questions:
                    break
                
                # VALIDATE: Check bubbles per row
                if len(row) != options_per_question:
                    print(f"âš ï¸  Question {question_num}: Expected {options_per_question} options, found {len(row)}")
                
                # ADAPTIVE FILL DETECTION: Compare each bubble against row average
                # This adapts to different lighting conditions automatically
                print(f"   Q{question_num}:", end="")
                filled_indices = []
                for option_idx, bubble in enumerate(row[:options_per_question]):
                    if self.check_if_filled_adaptive(processed, row[:options_per_question], option_idx):
                        filled_indices.append(option_idx)
                
                # CevabÄ± belirle
                if len(filled_indices) == 0:
                    answers[question_num] = 'BOÅ'
                    print(f" â†’ BOÅ")
                elif len(filled_indices) == 1:
                    answers[question_num] = option_letters[filled_indices[0]]
                    print(f" â†’ {option_letters[filled_indices[0]]}")
                else:
                    # Birden fazla iÅŸaretleme - hata
                    multiple_answers = [option_letters[i] for i in filled_indices]
                    print(f" â†’ HATALI (Multiple: {', '.join(multiple_answers)})")
                    answers[question_num] = 'HATALI'
            
            return {
                'success': True,
                'answers': answers,
                'total_bubbles_found': len(bubbles),
                'rows_found': len(rows),
                'questions_detected': len(answers)
            }
            
        except Exception as e:
            return {'error': f'GÃ¶rÃ¼ntÃ¼ iÅŸleme hatasÄ±: {str(e)}'}
    
    def detect_student_info(self, image_path: str) -> Dict:
        """
        Ã–ÄŸrenci bilgilerini (ad, numara) optik formdan oku
        Bu basitleÅŸtirilmiÅŸ bir versiyondur - gerÃ§ek uygulamada OCR kullanÄ±labilir
        """
        # Bu kÄ±sÄ±m iÃ§in geliÅŸmiÅŸ OCR (pytesseract) kullanÄ±labilir
        # Åimdilik basit bir implementasyon
        return {
            'student_name': 'Ad OCR ile okunacak',
            'student_number': 'Numara OCR ile okunacak'
        }
    
    def draw_results(self, image_path: str, answers: Dict, output_path: str):
        """
        SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼ Ã¼zerine Ã§iz
        """
        image = cv2.imread(image_path)
        
        # SonuÃ§larÄ± yazdÄ±r
        y_offset = 30
        for question, answer in answers.items():
            text = f"S{question}: {answer}"
            cv2.putText(image, text, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            y_offset += 30
        
        cv2.imwrite(output_path, image)
        return output_path


class AdvancedFormReader(OpticalFormReader):
    """
    Daha geliÅŸmiÅŸ form okuma - perspektif dÃ¼zeltme, form tespiti
    Timing mark bazlÄ± hizalama desteÄŸi
    """
    
    def detect_timing_marks(self, image):
        """
        LGS formundaki soldaki dikey timing mark'larÄ± tespit et
        
        Bu timing mark'lar:
        - Formun sol kenarÄ±nda dikey sÄ±rada
        - Siyah dikdÃ¶rtgen ÅŸekiller
        - Form hizalamasÄ± iÃ§in referans noktalarÄ±
        
        Returns:
            List[Tuple]: Timing mark merkezlerinin koordinatlarÄ± [(x,y), ...]
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Threshold: Siyah timing mark'larÄ± beyaz arka plandan ayÄ±r
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # Morfolojik iÅŸlem: KÃ¼Ã§Ã¼k gÃ¼rÃ¼ltÃ¼leri temizle
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # KontÃ¼rleri bul
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        timing_marks = []
        image_height, image_width = image.shape[:2]
        
        # Sol %15'lik bÃ¶lgede timing mark'larÄ± ara
        left_boundary = int(image_width * 0.15)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # Timing mark boyutu kontrolÃ¼ (100-1000 piksel arasÄ±)
            if 100 < area < 1000:
                x, y, w, h = cv2.boundingRect(contour)
                
                # Sol bÃ¶lgede mi?
                if x < left_boundary:
                    # En/boy oranÄ± kontrolÃ¼ (dikey dikdÃ¶rtgen)
                    aspect_ratio = h / float(w) if w > 0 else 0
                    
                    # Dikey dikdÃ¶rtgen: yÃ¼kseklik > geniÅŸlik (oran > 1.5)
                    if aspect_ratio > 1.5:
                        center_x = x + w // 2
                        center_y = y + h // 2
                        timing_marks.append({
                            'center': (center_x, center_y),
                            'bbox': (x, y, w, h),
                            'area': area
                        })
        
        # Y koordinatÄ±na gÃ¶re sÄ±rala (yukarÄ±dan aÅŸaÄŸÄ±ya)
        timing_marks.sort(key=lambda m: m['center'][1])
        
        print(f"ğŸ¯ {len(timing_marks)} timing mark bulundu")
        return timing_marks
    
    def detect_form_corners_with_timing_marks(self, image, debug=False):
        """
        Timing mark'larÄ± kullanarak form kÃ¶ÅŸelerini tespit et
        
        YÃ¶ntem:
        1. Soldaki timing mark'larÄ± bul
        2. Timing mark kalitesini kontrol et
        3. Timing mark'larÄ±n dikey hizalamasÄ±ndan eÄŸimi hesapla
        4. Form kenarlarÄ±nÄ± timing mark'lara gÃ¶re belirle
        5. 4 kÃ¶ÅŸe noktasÄ± dÃ¶ndÃ¼r
        
        Args:
            image: GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼
            debug: Debug gÃ¶rselleÅŸtirme aktif mi?
        
        Returns:
            corners: 4 kÃ¶ÅŸe noktasÄ± veya None
        """
        timing_marks = self.detect_timing_marks(image)
        
        if len(timing_marks) < 3:
            print("âš ï¸ Yeterli timing mark bulunamadÄ±, alternatif metod kullanÄ±lÄ±yor")
            return self.detect_form_corners(image)  # Fallback
        
        # Timing mark kalitesini kontrol et
        is_valid, message = self.validate_timing_marks(timing_marks)
        if not is_valid:
            print(f"âš ï¸ Timing mark kalitesi dÃ¼ÅŸÃ¼k: {message}")
            print("   Alternatif metod kullanÄ±lÄ±yor...")
            return self.detect_form_corners(image)  # Fallback
        
        print(f"âœ… Timing mark kalitesi: {message}")
        
        # DEBUG: Always save timing marks visualization
        self.visualize_timing_marks(image, timing_marks, 'debug_timing_marks.jpg')
        print("ğŸ’¾ Saved: debug_timing_marks.jpg")
        
        # Timing mark merkezlerini al
        points = np.array([m['center'] for m in timing_marks])
        
        # En az kareler yÃ¶ntemi ile doÄŸru fit et (sol kenar)
        # x = m*y + c formÃ¼lÃ¼ (y baÄŸÄ±msÄ±z deÄŸiÅŸken Ã§Ã¼nkÃ¼ dikey Ã§izgi)
        x_coords = points[:, 0]
        y_coords = points[:, 1]
        
        # Polinom fit (1. derece = doÄŸru)
        coeffs = np.polyfit(y_coords, x_coords, 1)
        m_left, c_left = coeffs  # EÄŸim ve kesiÅŸim
        
        # EÄŸim aÃ§Ä±sÄ± (derece cinsinden)
        angle_deg = np.degrees(np.arctan(m_left))
        print(f"ğŸ“ Sol kenar eÄŸimi: {angle_deg:.2f}Â°")
        
        # Ã‡ok eÄŸikse uyarÄ± ver
        if abs(angle_deg) > 15:
            print(f"âš ï¸ Form Ã§ok eÄŸik ({angle_deg:.1f}Â°), dÃ¼zeltme zor olabilir")
        
        # Form boyutlarÄ±nÄ± tahmin et
        height, width = image.shape[:2]
        
        # Ä°lk ve son timing mark'tan form sÄ±nÄ±rlarÄ±nÄ± belirle
        # Padding: Timing mark'lar formun tam kenarÄ±nda deÄŸil, biraz iÃ§erde
        top_padding = 100  # Ãœst kenara kadar mesafe
        bottom_padding = 100  # Alt kenara kadar mesafe
        
        top_y = max(0, timing_marks[0]['center'][1] - top_padding)
        bottom_y = min(height, timing_marks[-1]['center'][1] + bottom_padding)
        
        # Sol kenardaki x koordinatlarÄ± (doÄŸru denklemi kullan)
        top_left_x = int(m_left * top_y + c_left)
        bottom_left_x = int(m_left * bottom_y + c_left)
        
        # Form geniÅŸliÄŸini tahmin et
        # LGS formu standart A4: en/boy â‰ˆ 1:1.41
        form_height = bottom_y - top_y
        form_width = int(form_height / 1.41)
        
        # SaÄŸ kenar da eÄŸimli olabilir (paralel)
        # Sol kenarla aynÄ± eÄŸimi kullan
        top_right_x = top_left_x + form_width
        bottom_right_x = bottom_left_x + form_width
        
        # 4 kÃ¶ÅŸe noktasÄ±
        corners = np.array([
            [top_left_x, top_y],              # Sol-Ã¼st
            [top_right_x, top_y],              # SaÄŸ-Ã¼st
            [bottom_right_x, bottom_y],        # SaÄŸ-alt
            [bottom_left_x, bottom_y]          # Sol-alt
        ], dtype=np.float32)
        
        print(f"âœ… Timing mark bazlÄ± kÃ¶ÅŸeler belirlendi: {form_width}x{form_height}")
        return corners
    
    def detect_form_corners(self, image):
        """
        KaÄŸÄ±t dokÃ¼man kÃ¶ÅŸelerini tespit et (OMR form sÄ±nÄ±rlarÄ±)
        
        Ã–NEMLÄ° DEÄÄ°ÅÄ°KLÄ°KLER:
        1. Canny parametreleri (50,150) â†’ (75,200)
           - Neden: KaÄŸÄ±t kenarlarÄ± dÃ¼ÅŸÃ¼k kontrastlÄ±, yÃ¼ksek threshold gerekir
        2. Daha bÃ¼yÃ¼k GaussianBlur (5,5) â†’ (7,7)
           - Neden: KaÄŸÄ±t dokusu gÃ¼rÃ¼ltÃ¼ yaratÄ±r, daha fazla bulanÄ±klÄ±k gerekir
        3. Dilation eklendi
           - Neden: Kesik kenarlarÄ± birleÅŸtirir, kÃ¶ÅŸe tespitini iyileÅŸtirir
        4. Minimum alan kontrolÃ¼
           - Neden: KÃ¼Ã§Ã¼k nesneleri (lekeler, gÃ¶lgeler) yoksayar
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Daha gÃ¼Ã§lÃ¼ blur: KaÄŸÄ±t dokusunu ve gÃ¼rÃ¼ltÃ¼yÃ¼ temizle
        blurred = cv2.GaussianBlur(gray, (7, 7), 0)
        
        # Canny edge detection - KAÄIT DOKÃœMANI Ä°Ã‡Ä°N OPTÄ°MÄ°ZE
        # Threshold1=75 (dÃ¼ÅŸÃ¼k): ZayÄ±f kenarlarÄ± yakala
        # Threshold2=200 (yÃ¼ksek): GÃ¼Ã§lÃ¼ kenarlarÄ± garantile
        # Oran 1:2.67 - kaÄŸÄ±t kenarlarÄ± iÃ§in ideal
        edged = cv2.Canny(blurred, 75, 200, apertureSize=3)
        
        # DEBUG: Save edges
        cv2.imwrite('debug_edges.jpg', edged)
        print("ğŸ’¾ Saved: debug_edges.jpg")
        
        # Dilation: Kesik kenarlarÄ± birleÅŸtir
        # KaÄŸÄ±t kÃ¶ÅŸeleri bazen kesik gÃ¶rÃ¼nÃ¼r, bu onlarÄ± kapatÄ±r
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        edged = cv2.dilate(edged, kernel, iterations=1)
        
        # KontÃ¼rleri bul
        contours, _ = cv2.findContours(
            edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        # DEBUG: Draw contours on original
        debug_contours = image.copy()
        cv2.drawContours(debug_contours, contours, -1, (0, 255, 0), 2)
        cv2.imwrite('debug_contours.jpg', debug_contours)
        print("ğŸ’¾ Saved: debug_contours.jpg")
        
        if not contours:
            return None
        
        # KonturlarÄ± alana gÃ¶re sÄ±rala (en bÃ¼yÃ¼k = form)
        contours = sorted(contours, key=cv2.contourArea, reverse=True)
        
        # Minimum alan kontrolÃ¼: GÃ¶rÃ¼ntÃ¼ alanÄ±nÄ±n en az %10'u olmalÄ±
        image_area = image.shape[0] * image.shape[1]
        min_area = image_area * 0.1
        
        # En bÃ¼yÃ¼k konturlarÄ± kontrol et
        for contour in contours[:5]:  # Ä°lk 5 konturu dene
            area = cv2.contourArea(contour)
            
            # Alan yeterince bÃ¼yÃ¼k mÃ¼?
            if area < min_area:
                continue
            
            # KontÃ¼rÃ¼ yaklaÅŸÄ±k dÃ¶rtgene dÃ¶nÃ¼ÅŸtÃ¼r
            peri = cv2.arcLength(contour, True)
            # epsilon=0.02: Daha esnek (eÄŸik/bozuk formlar iÃ§in)
            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
            
            # 4 kÃ¶ÅŸeli bir ÅŸekil bulduk mu?
            if len(approx) == 4:
                return approx.reshape(4, 2)
        
        return None
    
    def apply_perspective_transform(self, image, corners):
        """
        Perspektif dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygula - formu dÃ¼zelt
        
        GeliÅŸmiÅŸ Ã¶zellikler:
        1. Timing mark bazlÄ± hizalama koruma
        2. Aspect ratio korumasÄ± (A4: 1:1.41)
        3. Otomatik padding (kenarlar kesikse)
        """
        # KÃ¶ÅŸeleri sÄ±rala: sol-Ã¼st, saÄŸ-Ã¼st, saÄŸ-alt, sol-alt
        rect = self.order_points(corners)
        (tl, tr, br, bl) = rect
        
        # GeniÅŸlik ve yÃ¼kseklik hesapla
        width_a = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
        width_b = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
        max_width = max(int(width_a), int(width_b))
        
        height_a = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
        height_b = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
        max_height = max(int(height_a), int(height_b))
        
        # A4 en/boy oranÄ±nÄ± koru (opsiyonel dÃ¼zeltme)
        expected_ratio = 1.41  # A4 oranÄ±
        current_ratio = max_height / max_width if max_width > 0 else 1
        
        # Oran sapmasÄ± %20'den fazlaysa dÃ¼zelt
        if abs(current_ratio - expected_ratio) / expected_ratio > 0.2:
            print(f"âš™ï¸ Aspect ratio dÃ¼zeltiliyor: {current_ratio:.2f} â†’ {expected_ratio:.2f}")
            if current_ratio > expected_ratio:
                # Ã‡ok uzun, geniÅŸliÄŸi artÄ±r
                max_width = int(max_height / expected_ratio)
            else:
                # Ã‡ok geniÅŸ, yÃ¼ksekliÄŸi artÄ±r
                max_height = int(max_width * expected_ratio)
        
        # Hedef noktalar (dÃ¼z dikdÃ¶rtgen)
        dst = np.array([
            [0, 0],
            [max_width - 1, 0],
            [max_width - 1, max_height - 1],
            [0, max_height - 1]
        ], dtype=np.float32)
        
        # Perspektif dÃ¶nÃ¼ÅŸÃ¼m matrisi
        M = cv2.getPerspectiveTransform(rect, dst)
        
        # Warp uygula
        warped = cv2.warpPerspective(
            image, M, (max_width, max_height),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(255, 255, 255)  # Beyaz padding
        )
        
        # DEBUG: Save warped result
        cv2.imwrite('debug_warped.jpg', warped)
        print("ğŸ’¾ Saved: debug_warped.jpg")
        
        print(f"âœ… Perspektif dÃ¼zeltildi: {warped.shape[1]}x{warped.shape[0]}")
        return warped
    
    def visualize_timing_marks(self, image, timing_marks, output_path='debug_timing_marks.jpg'):
        """
        Debug: Timing mark'larÄ± gÃ¶rselleÅŸtir
        """
        debug_img = image.copy()
        
        for i, mark in enumerate(timing_marks):
            cx, cy = mark['center']
            x, y, w, h = mark['bbox']
            
            # Timing mark'Ä± Ã§erÃ§evele
            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            # Merkezi iÅŸaretle
            cv2.circle(debug_img, (cx, cy), 5, (0, 0, 255), -1)
            
            # Numara yaz
            cv2.putText(debug_img, str(i+1), (x-20, cy), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # DoÄŸru fit et (varsa)
        if len(timing_marks) >= 2:
            points = np.array([m['center'] for m in timing_marks])
            y_coords = points[:, 1]
            x_coords = points[:, 0]
            
            coeffs = np.polyfit(y_coords, x_coords, 1)
            m, c = coeffs
            
            # DoÄŸruyu Ã§iz
            y1, y2 = int(y_coords.min()), int(y_coords.max())
            x1 = int(m * y1 + c)
            x2 = int(m * y2 + c)
            cv2.line(debug_img, (x1, y1), (x2, y2), (255, 0, 255), 2)
        
        cv2.imwrite(output_path, debug_img)
        print(f"ğŸ¨ Debug gÃ¶rsel kaydedildi: {output_path}")
        
        return debug_img
    
    def validate_timing_marks(self, timing_marks):
        """
        Timing mark'larÄ±n kalitesini kontrol et
        
        Returns:
            bool: Timing mark'lar geÃ§erli mi?
            str: Hata mesajÄ± (varsa)
        """
        if len(timing_marks) < 3:
            return False, f"Yetersiz timing mark: {len(timing_marks)}<3"
        
        # Y koordinatlarÄ±nÄ±n dÃ¼zenli aralÄ±klÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        y_coords = [m['center'][1] for m in timing_marks]
        
        if len(y_coords) >= 2:
            # ArdÄ±ÅŸÄ±k timing mark'lar arasÄ± mesafeler
            distances = [y_coords[i+1] - y_coords[i] for i in range(len(y_coords)-1)]
            avg_distance = np.mean(distances)
            std_distance = np.std(distances)
            
            # Standart sapma ortalamadan %30'dan fazla farklÄ±ysa sorunlu
            if std_distance > avg_distance * 0.3:
                return False, f"DÃ¼zensiz aralÄ±k: std={std_distance:.1f}, avg={avg_distance:.1f}"
        
        # X koordinatlarÄ±nÄ±n yaklaÅŸÄ±k aynÄ± hizada olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        x_coords = [m['center'][0] for m in timing_marks]
        x_std = np.std(x_coords)
        
        # X sapmasÄ± 20 pikselden fazlaysa Ã§ok eÄŸik
        if x_std > 20:
            return False, f"Ã‡ok eÄŸik: x_std={x_std:.1f}>20"
        
        return True, "OK"
    
    def order_points(self, pts):
        """
        NoktalarÄ± sÄ±rala: sol-Ã¼st, saÄŸ-Ã¼st, saÄŸ-alt, sol-alt
        """
        rect = np.zeros((4, 2), dtype=np.float32)
        
        # ToplamlarÄ± ve farklarÄ±nÄ± hesapla
        s = pts.sum(axis=1)
        diff = np.diff(pts, axis=1)
        
        rect[0] = pts[np.argmin(s)]      # Sol-Ã¼st
        rect[2] = pts[np.argmax(s)]      # SaÄŸ-alt
        rect[1] = pts[np.argmin(diff)]   # SaÄŸ-Ã¼st
        rect[3] = pts[np.argmax(diff)]   # Sol-alt
        
        return rect
